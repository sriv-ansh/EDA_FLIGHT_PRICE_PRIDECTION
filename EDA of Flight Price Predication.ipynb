{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cf7419",
   "metadata": {},
   "source": [
    "## Flight Price Predication EDA and Feature Engineering \n",
    "![](https://wallup.net/wp-content/uploads/2019/09/344761-boeing-747-airliner-aircraft-plane-airplane-boeing-747-transport-36-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1df56",
   "metadata": {},
   "source": [
    "### 1) About the Dataset\n",
    "    The objective of the study is to analyse the flight booking dataset obtained from “Ease My Trip” website and to conduct\n",
    "    various statistical hypothesis tests in order to get meaningful information from it.Easemytrip' is an internet platform\n",
    "    for booking flight tickets, and hence a platform that potential passengers use to buy tickets. A thorough study of the\n",
    "    data will aid in the discovery of valuable insights that will be of enormous value to passengers.\n",
    "\n",
    "### 2) Data Collection \n",
    "   We Collected the data from kaggle :- https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction\n",
    "\n",
    "### 3) Info about the dataset\n",
    "    The Dataset contains information about flight booking options from the website Easemytrip for travel between India's 6 metro cities. There are 10683 datapoints and 11 feature \n",
    "\n",
    "### 3) Feature :- Let's Explore some feature in our dataset\n",
    "* 1) **Airline :-** The name of airline company stored in Airline columns.\n",
    "* 2) **Date_of_Journey :-** Date of the Journey.\n",
    "* 3) **Source :-** Source City where Flight Take Off.\n",
    "* 4) **Destination :-** The City Where Flight will be Arrival.\n",
    "* 5) **Route :-** The Flight Rought.\n",
    "* 6) **Dep_Time :-** The Departure Time of the Flight. \n",
    "* 7) **Arrival_Time :-** The Arrival Time of the Flight.\n",
    "* 8) **Duration :-** A time which has been taken to Department time to Arrival Time of flight.\n",
    "* 9) **Total_Stops :-** Total Stops of flight between Source and Destination location. \n",
    "* 10) **Additional_info :-** If there is any additional info avaliable.\n",
    "* 11) **Price :-** Target Variable store information about Ticket Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853eb0ee",
   "metadata": {},
   "source": [
    "#### Importing the Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296eb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import scipy.stats as sts\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a784493",
   "metadata": {},
   "source": [
    "#### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80cc47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n",
       "1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n",
       "2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n",
       "3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n",
       "4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897  \n",
       "1    05:50         13:15   7h 25m     2 stops         No info   7662  \n",
       "2    09:25  04:25 10 Jun      19h     2 stops         No info  13882  \n",
       "3    18:05         23:30   5h 25m      1 stop         No info   6218  \n",
       "4    16:50         21:35   4h 45m      1 stop         No info  13302  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"flight_data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be154f93",
   "metadata": {},
   "source": [
    "#### Shape of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7164db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb10927",
   "metadata": {},
   "source": [
    "#### Let's grab some infomation about the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61272516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb19de",
   "metadata": {},
   "source": [
    "**Observation:-** As we have seen all the datatypes has been object for the better feature engineering we'll try to perform some data cleaning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e8b9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Firstly we'll start with Feature Date_of_Journey\n",
    "df['Date_of_Journey'] = pd.to_datetime(df['Date_of_Journey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13b10a",
   "metadata": {},
   "source": [
    "**Actions:-** \n",
    "* We have convert Date_of_Journey from object type to datetime format\n",
    "* Now our Next steps to extract the Year , Month , Day into different Feature and we'll store into int datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa19f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year_of_Journey'] = df['Date_of_Journey'].dt.year\n",
    "df['Months_of_Journey'] = df['Date_of_Journey'].dt.month\n",
    "df['Day_of_Journey'] = df['Date_of_Journey'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49879e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Date_of_Journey\",\"Year\"],axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78950a2a",
   "metadata": {},
   "source": [
    "**Till Now We Had Convert Year_of_Journey with is object type and we had convert into Datetimes and we have sptil Day , Month , Year and All the columns has been convert into int type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a6969b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Deperature_Hours'] =  df['Dep_Time'].str[0:2].astype(int)\n",
    "df['Deperature_Minutes'] = df['Dep_Time'].str[3:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0157db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Dep_Time',axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d0780",
   "metadata": {},
   "source": [
    "**Here we had split the Deperature_Time into two feature Deperature_Hours and Deperture_Minitues as we also convert that into int datatype.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6000689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Arrival_Time'] = df['Arrival_Time'].apply(lambda x :x[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b5096c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Arrival_Hours'] = df['Arrival_Time'].str[0:2].astype(int)\n",
    "df['Arrival_Miniutes'] = df['Arrival_Time'].str[3::].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad14ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Arrival_Time',axis= 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604a032",
   "metadata": {},
   "source": [
    "**Here we had split the Deperature_Time into two feature Arrival_Hours and Arrival_Minitues as we also convert that into int datatype.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "02ba3c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2h 50m\n",
       "1        7h 25m\n",
       "2           19h\n",
       "3        5h 25m\n",
       "4        4h 45m\n",
       "          ...  \n",
       "10678    2h 30m\n",
       "10679    2h 35m\n",
       "10680        3h\n",
       "10681    2h 40m\n",
       "10682    8h 20m\n",
       "Name: Duration, Length: 10683, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1a7ebcce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Hour'] =  df['Duration'].apply(lambda x : x[0:3].replace(\"h\",\"\") or x[0:3].replace(\"m\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f65f825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Route',axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "458fdd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(6474,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d9037d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['Hour'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "de04b328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'Hour':\"Duration Hour\"},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e97195cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration Miniutes'] = df['Duration'].str.split(\" \").apply(lambda x :int(x[-1].replace(\"m\",\"\"))  if 'm' in x[-1][-1] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4c5d0ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df['Duration']:\n",
    "    j = i.split(\" \")\n",
    "    if 'm' in j[-1][-1]:\n",
    "        l.append(int(j[-1].replace(\"m\",\"\")))\n",
    "    else:\n",
    "        l.append(0)\n",
    "## Here I've expend the above function for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "54f8c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Duration',axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dc96dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Additional_Info\",axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647b344",
   "metadata": {},
   "source": [
    "### Our Dataset Has Been Cleaned here Now We'll Move Forword to encoder technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c4f14576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-stop', '2 stops', '1 stop', '3 stops', nan, '4 stops'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['Total_Stops'].unique())\n",
    "display(df['Total_Stops'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8197a",
   "metadata": {},
   "source": [
    "**Observation:-** As We have observed the it's totally Categorical Variable and we'll Encode these values with Target Guided Encoder Which will be suitable Encoder Technique for **Total_Stops** Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "71fb9046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 stop'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Total_Stops'].notna()]['Total_Stops'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b24c8",
   "metadata": {},
   "source": [
    "**Observation:-** We have Observed that in **Total_Stops** Features  Mode Value is **1 stop**. so while Encoding whereever the values is nan we'll compute with **1 stop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "df9a4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target Guided Encoder \n",
    "df['Total_Stops'].replace({\"non-stop\":0,\"1 stop\":1,\"2 stops\":2,\"3 stops\":3,\"4 stops\":4,np.nan:1},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5c93b",
   "metadata": {},
   "source": [
    "**Observation / Action:-** We have Encode the **Total_Stops** Feature with some values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a204c",
   "metadata": {},
   "source": [
    "#### Now We'll Encode the Airline , Source and Destination columns using some technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ea406def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Airline Unique Values:- ['IndiGo' 'Air India' 'Jet Airways' 'SpiceJet' 'Multiple carriers' 'GoAir'\\n 'Vistara' 'Air Asia' 'Vistara Premium economy' 'Jet Airways Business'\\n 'Multiple carriers Premium economy' 'Trujet']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Source Unique Values:- ['Banglore' 'Kolkata' 'Delhi' 'Chennai' 'Mumbai']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Destination Unique Values:- ['New Delhi' 'Banglore' 'Cochin' 'Kolkata' 'Delhi' 'Hyderabad']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[0:3]:\n",
    "    display(f\"{i} Unique Values:- {df[i].unique()}\")\n",
    "    print(df[i].nunique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1014c9",
   "metadata": {},
   "source": [
    "**Observation & Action:-** Here we have observed that Airline have total 12 Unique Values and Source Having 5 and Destination having 6 Unique Values in the Feature Airline , Source and Destination so we'll compute the values with some Imputer.\n",
    "\n",
    "The Suitable Encoder technique will be these columns is OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d305c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "758c82c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE = OneHotEncoder()\n",
    "OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b6140eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OHE.fit_transform(df[['Airline','Source','Destination']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "4d7aba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df,pd.DataFrame(encoder,columns= OHE.get_feature_names_out())],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "bb463186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[0:3],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "922764fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>Year_of_Journey</th>\n",
       "      <th>Months_of_Journey</th>\n",
       "      <th>Day_of_Journey</th>\n",
       "      <th>Deperature_Time</th>\n",
       "      <th>Deperature_Minutes</th>\n",
       "      <th>Arrival_Hours</th>\n",
       "      <th>Arrival_Miniutes</th>\n",
       "      <th>Duration Hour</th>\n",
       "      <th>...</th>\n",
       "      <th>Source_Chennai</th>\n",
       "      <th>Source_Delhi</th>\n",
       "      <th>Source_Kolkata</th>\n",
       "      <th>Source_Mumbai</th>\n",
       "      <th>Destination_Banglore</th>\n",
       "      <th>Destination_Cochin</th>\n",
       "      <th>Destination_Delhi</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3897.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7662.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13882.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6218.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13302.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops    Price  Year_of_Journey  Months_of_Journey  Day_of_Journey  \\\n",
       "0          0.0   3897.0           2019.0                3.0            24.0   \n",
       "1          2.0   7662.0           2019.0                5.0             1.0   \n",
       "2          2.0  13882.0           2019.0                6.0             9.0   \n",
       "3          1.0   6218.0           2019.0                5.0            12.0   \n",
       "4          1.0  13302.0           2019.0                3.0             1.0   \n",
       "\n",
       "   Deperature_Time  Deperature_Minutes  Arrival_Hours  Arrival_Miniutes  \\\n",
       "0             22.0                20.0            1.0              10.0   \n",
       "1              5.0                50.0           13.0              15.0   \n",
       "2              9.0                25.0            4.0              25.0   \n",
       "3             18.0                 5.0           23.0              30.0   \n",
       "4             16.0                50.0           21.0              35.0   \n",
       "\n",
       "   Duration Hour  ...  Source_Chennai  Source_Delhi  Source_Kolkata  \\\n",
       "0            2.0  ...             0.0           0.0             0.0   \n",
       "1            7.0  ...             0.0           0.0             1.0   \n",
       "2           19.0  ...             0.0           1.0             0.0   \n",
       "3            5.0  ...             0.0           0.0             1.0   \n",
       "4            4.0  ...             0.0           0.0             0.0   \n",
       "\n",
       "   Source_Mumbai  Destination_Banglore  Destination_Cochin  Destination_Delhi  \\\n",
       "0            0.0                   0.0                 0.0                0.0   \n",
       "1            0.0                   1.0                 0.0                0.0   \n",
       "2            0.0                   0.0                 1.0                0.0   \n",
       "3            0.0                   1.0                 0.0                0.0   \n",
       "4            0.0                   0.0                 0.0                0.0   \n",
       "\n",
       "   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n",
       "0                    0.0                  0.0                    1.0  \n",
       "1                    0.0                  0.0                    0.0  \n",
       "2                    0.0                  0.0                    0.0  \n",
       "3                    0.0                  0.0                    0.0  \n",
       "4                    0.0                  0.0                    1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f85f4a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10683 entries, 0 to 6474\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Total_Stops                                10682 non-null  float64\n",
      " 1   Price                                      10682 non-null  float64\n",
      " 2   Year_of_Journey                            10682 non-null  float64\n",
      " 3   Months_of_Journey                          10682 non-null  float64\n",
      " 4   Day_of_Journey                             10682 non-null  float64\n",
      " 5   Deperature_Time                            10682 non-null  float64\n",
      " 6   Deperature_Minutes                         10682 non-null  float64\n",
      " 7   Arrival_Hours                              10682 non-null  float64\n",
      " 8   Arrival_Miniutes                           10682 non-null  float64\n",
      " 9   Duration Hour                              10682 non-null  float64\n",
      " 10  Duration Miniutes                          10682 non-null  float64\n",
      " 11  Airline_Air Asia                           10682 non-null  float64\n",
      " 12  Airline_Air India                          10682 non-null  float64\n",
      " 13  Airline_GoAir                              10682 non-null  float64\n",
      " 14  Airline_IndiGo                             10682 non-null  float64\n",
      " 15  Airline_Jet Airways                        10682 non-null  float64\n",
      " 16  Airline_Jet Airways Business               10682 non-null  float64\n",
      " 17  Airline_Multiple carriers                  10682 non-null  float64\n",
      " 18  Airline_Multiple carriers Premium economy  10682 non-null  float64\n",
      " 19  Airline_SpiceJet                           10682 non-null  float64\n",
      " 20  Airline_Trujet                             10682 non-null  float64\n",
      " 21  Airline_Vistara                            10682 non-null  float64\n",
      " 22  Airline_Vistara Premium economy            10682 non-null  float64\n",
      " 23  Source_Banglore                            10682 non-null  float64\n",
      " 24  Source_Chennai                             10682 non-null  float64\n",
      " 25  Source_Delhi                               10682 non-null  float64\n",
      " 26  Source_Kolkata                             10682 non-null  float64\n",
      " 27  Source_Mumbai                              10682 non-null  float64\n",
      " 28  Destination_Banglore                       10682 non-null  float64\n",
      " 29  Destination_Cochin                         10682 non-null  float64\n",
      " 30  Destination_Delhi                          10682 non-null  float64\n",
      " 31  Destination_Hyderabad                      10682 non-null  float64\n",
      " 32  Destination_Kolkata                        10682 non-null  float64\n",
      " 33  Destination_New Delhi                      10682 non-null  float64\n",
      "dtypes: float64(34)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cda42",
   "metadata": {},
   "source": [
    "### Here we go \n",
    "* We have completed our Flight Price Pridication Data Cleaning and Feature Engineering Sucessfully.\n",
    "* Now We can create the predictive model on that data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
